{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-02T04:41:08.191358Z","iopub.execute_input":"2025-01-02T04:41:08.191579Z","iopub.status.idle":"2025-01-02T04:41:08.485256Z","shell.execute_reply.started":"2025-01-02T04:41:08.191553Z","shell.execute_reply":"2025-01-02T04:41:08.484614Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install transformers==4.47.1 accelerate==0.34.2 bitsandbytes==0.45.0 trl==0.13.0 datasets==3.2.0 peft==0.14.0 tokenizers==0.21.0 huggingface_hub==0.26.0 -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T04:52:15.988723Z","iopub.execute_input":"2025-01-02T04:52:15.989035Z","iopub.status.idle":"2025-01-02T04:52:35.810277Z","shell.execute_reply.started":"2025-01-02T04:52:15.989006Z","shell.execute_reply":"2025-01-02T04:52:35.809065Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.4/293.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, BitsAndBytesConfig\nimport torch\nfrom datasets import load_dataset\nfrom transformers import Trainer, TrainingArguments\nfrom peft import PeftModel,get_peft_model,LoraConfig, TaskType\nfrom trl import SFTTrainer, SFTConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T04:52:52.882244Z","iopub.execute_input":"2025-01-02T04:52:52.882564Z","iopub.status.idle":"2025-01-02T04:53:10.788412Z","shell.execute_reply.started":"2025-01-02T04:52:52.882537Z","shell.execute_reply":"2025-01-02T04:53:10.787540Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HuggigFace\") # Fetching the Hugging Face token from the Kaggle Secret keys add on\nlogin(token = hf_token) # Logging into Hugging ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T04:53:14.405464Z","iopub.execute_input":"2025-01-02T04:53:14.405829Z","iopub.status.idle":"2025-01-02T04:53:14.694814Z","shell.execute_reply.started":"2025-01-02T04:53:14.405803Z","shell.execute_reply":"2025-01-02T04:53:14.693845Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### setup model and bnb config","metadata":{}},{"cell_type":"code","source":"base_model = \"meta-llama/Llama-3.2-3B-Instruct\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T04:53:16.403892Z","iopub.execute_input":"2025-01-02T04:53:16.404210Z","iopub.status.idle":"2025-01-02T04:53:16.407934Z","shell.execute_reply.started":"2025-01-02T04:53:16.404183Z","shell.execute_reply":"2025-01-02T04:53:16.407030Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable loading the model with 4-bit precision for reduced memory usage\n    bnb_4bit_quant_type='nf4',  # Use NormalFloat4 (nf4), a quantization format for higher accuracy\n    bnb_4bit_compute_dtype=torch.float16,  # Use float16 for computation to balance speed and precision\n    bnb_4bit_use_double_quant=True  # Enable double quantization for better numerical stability\n)\n\n# Load the pre-trained model with 4-bit quantization\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,  # Name of the base model defined earlier\n    device_map=\"auto\",  # Automatically map model layers to available devices (e.g., GPU/CPU)\n    quantization_config=bnb_config,  # Apply the defined 4-bit quantization configuration\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T04:53:19.319053Z","iopub.execute_input":"2025-01-02T04:53:19.319386Z","iopub.status.idle":"2025-01-02T04:56:01.887844Z","shell.execute_reply.started":"2025-01-02T04:53:19.319358Z","shell.execute_reply":"2025-01-02T04:56:01.886917Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb344184970641b090fc67f61997d8fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a79e9d7514b04079b5fb622eb8b11a40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e63df2ab3ce24bd49c1fa4aedfd9607f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5c0b696505f496f944d379bf8235f07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd11df335b6b47b6940b1c28ade5d240"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf258150db14447abb34ba28a07cfda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f41e5476094f48e2957ccea9aaaead6c"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# add tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T04:56:01.888935Z","iopub.execute_input":"2025-01-02T04:56:01.889184Z","iopub.status.idle":"2025-01-02T04:56:03.536671Z","shell.execute_reply.started":"2025-01-02T04:56:01.889162Z","shell.execute_reply":"2025-01-02T04:56:03.535732Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5047f34ae0e24a7dbf1d0eefe021d0d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3d055c2830544cbac996740cef5718a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e027447295e4281ae7aeaa851a450d0"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### Load the dataset","metadata":{}},{"cell_type":"code","source":"db = \"NebulaByte/E-Commerce_Customer_Support_Conversations\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T06:27:39.857264Z","iopub.execute_input":"2025-01-02T06:27:39.857600Z","iopub.status.idle":"2025-01-02T06:27:39.861035Z","shell.execute_reply.started":"2025-01-02T06:27:39.857571Z","shell.execute_reply":"2025-01-02T06:27:39.860220Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# find the customer support dataset and load into the cell\ndataset = load_dataset(db, split=\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T06:28:04.625644Z","iopub.execute_input":"2025-01-02T06:28:04.625924Z","iopub.status.idle":"2025-01-02T06:28:05.332520Z","shell.execute_reply.started":"2025-01-02T06:28:04.625903Z","shell.execute_reply":"2025-01-02T06:28:05.331902Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T06:28:06.614608Z","iopub.execute_input":"2025-01-02T06:28:06.614923Z","iopub.status.idle":"2025-01-02T06:28:06.619741Z","shell.execute_reply.started":"2025-01-02T06:28:06.614898Z","shell.execute_reply":"2025-01-02T06:28:06.618998Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['issue_area', 'issue_category', 'issue_sub_category', 'issue_category_sub_category', 'customer_sentiment', 'product_category', 'product_sub_category', 'issue_complexity', 'agent_experience_level', 'agent_experience_level_desc', 'conversation'],\n    num_rows: 1000\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"dataset = dataset.remove_columns(['issue_area','issue_sub_category', 'issue_category_sub_category',\n                                  'customer_sentiment', 'product_category', 'product_sub_category', \n                                  'issue_complexity', 'agent_experience_level'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T06:28:09.088144Z","iopub.execute_input":"2025-01-02T06:28:09.088441Z","iopub.status.idle":"2025-01-02T06:28:09.094656Z","shell.execute_reply.started":"2025-01-02T06:28:09.088419Z","shell.execute_reply":"2025-01-02T06:28:09.093760Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"dataset.train_test_split(test_size=0.20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T06:28:10.090172Z","iopub.execute_input":"2025-01-02T06:28:10.090456Z","iopub.status.idle":"2025-01-02T06:28:10.107630Z","shell.execute_reply.started":"2025-01-02T06:28:10.090435Z","shell.execute_reply":"2025-01-02T06:28:10.106925Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['issue_category', 'agent_experience_level_desc', 'conversation'],\n        num_rows: 800\n    })\n    test: Dataset({\n        features: ['issue_category', 'agent_experience_level_desc', 'conversation'],\n        num_rows: 200\n    })\n})"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"### Tokenize the dataset","metadata":{}},{"cell_type":"code","source":"# set the instructions \ninstruction = \"\"\"You are helpful and efficient e-commerce customer support assistant bot designed to assist users by providing answers to frequently asked questions (FAQs) related to our products and services. Your responses should be concise, clear, and friendly, ensuring the user feels heard and supported. If the user’s question is outside the scope of the FAQ, gently direct them to contact customer support.\n\nAlways prioritize accuracy and clarity in your answers.\nIf the user asks a complex question, break it down into smaller, manageable parts and answer step-by-step.\nProvide useful links or references to detailed documentation when appropriate.\nUse a friendly and professional tone, ensuring the response is easy to understand.\nIf the FAQ does not cover the question, offer an apology and suggest contacting customer support.\n\"\"\"\n\ndef template(row):\n\n    row_json = [{\"role\":\"system\", \"content\":instruction},\n                {\"role\":\"category\", \"content\":row[\"issue_category\"]},\n                {\"role\":\"user\", \"content\":row[\"agent_experience_level_desc\"]},\n                {\"role\":\"assistant\", \"content\": row[\"conversation\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:47:12.556693Z","iopub.execute_input":"2025-01-02T07:47:12.557000Z","iopub.status.idle":"2025-01-02T07:47:12.561979Z","shell.execute_reply.started":"2025-01-02T07:47:12.556978Z","shell.execute_reply":"2025-01-02T07:47:12.561275Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"dataset = dataset.map(template,num_proc= 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:47:34.543872Z","iopub.execute_input":"2025-01-02T07:47:34.544157Z","iopub.status.idle":"2025-01-02T07:47:35.270198Z","shell.execute_reply.started":"2025-01-02T07:47:34.544136Z","shell.execute_reply":"2025-01-02T07:47:35.269371Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6b6d4097b8457087f71eb6376750a5"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:58:36.832033Z","iopub.execute_input":"2025-01-02T07:58:36.832341Z","iopub.status.idle":"2025-01-02T07:58:36.845424Z","shell.execute_reply.started":"2025-01-02T07:58:36.832317Z","shell.execute_reply":"2025-01-02T07:58:36.844563Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"dataset[\"train\"][\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T07:58:49.753320Z","iopub.execute_input":"2025-01-02T07:58:49.753663Z","iopub.status.idle":"2025-01-02T07:58:49.768011Z","shell.execute_reply.started":"2025-01-02T07:58:49.753633Z","shell.execute_reply":"2025-01-02T07:58:49.767172Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 02 Jan 2025\\n\\nYou are helpful and efficient e-commerce customer support assistant bot designed to assist users by providing answers to frequently asked questions (FAQs) related to our products and services. Your responses should be concise, clear, and friendly, ensuring the user feels heard and supported. If the user’s question is outside the scope of the FAQ, gently direct them to contact customer support.\\n\\nAlways prioritize accuracy and clarity in your answers.\\nIf the user asks a complex question, break it down into smaller, manageable parts and answer step-by-step.\\nProvide useful links or references to detailed documentation when appropriate.\\nUse a friendly and professional tone, ensuring the response is easy to understand.\\nIf the FAQ does not cover the question, offer an apology and suggest contacting customer support.<|eot_id|><|start_header_id|>category<|end_header_id|>\\n\\nAccount and Shopping<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nmay struggle with ambiguous queries, rely on clarification from customers or guidance from senior team members, find it difficult to de-escalate tense situations, and may rely on predefined steps or escalate to supervisors for support<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAgent: Thank you for calling BrownBox Customer Support. My name is Sarah. How may I assist you today?\\n\\nCustomer: Hi Sarah, I recently purchased a BP monitor from your website and I noticed that there were some hidden charges that I wasn't aware of. Can you please explain why that happened?\\n\\nAgent: I'm sorry to hear that you had some hidden charges on your purchase. Can you please provide me with your order number so that I can look into this for you?\\n\\nCustomer: Sure, it's #123456.\\n\\nAgent: Thank you for providing the details. I apologize for any confusion caused by the hidden charges. May I know which charges you are referring to?\\n\\nCustomer: There was an additional charge of $10 that I wasn't aware of when I placed the order. Can you please explain why that happened?\\n\\nAgent: I'm sorry for the confusion. Upon checking, I see that the additional charge was for the shipping and handling of the product. This charge is mentioned on the checkout page before you place the order. However, I understand that it may not have been clear to you, and I apologize for that.\\n\\nCustomer: Oh, I see. I must have missed that. Is there any way to get a refund for that charge?\\n\\nAgent: I'm afraid that the shipping and handling charges are non-refundable. However, I can offer you a discount code for your next purchase as a gesture of goodwill. Would that be okay with you?\\n\\nCustomer: Yes, that would be great. Thank you.\\n\\nAgent: Sure thing. I will send you an email with the discount code shortly. Is there anything else I can assist you with?\\n\\nCustomer: No, that's all for now. Thank you for your help, Sarah.\\n\\nAgent: You're welcome. If you have any other questions or concerns, please don't hesitate to contact us. Have a great day!\\n\\nCustomer: You too, Sarah. Goodbye.\\n\\nAgent: Goodbye.<|eot_id|>\""},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"### set the lora config and train the model","metadata":{}},{"cell_type":"code","source":"lora_config = LoraConfig(r=4, \n                         lora_alpha=8, \n                         lora_dropout=0.2,\n                        task_type=\"CAUSAL_LM\")\n\nmodel = get_peft_model(model, lora_config)\n\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:26:20.748102Z","iopub.execute_input":"2025-01-02T08:26:20.748410Z","iopub.status.idle":"2025-01-02T08:26:20.845417Z","shell.execute_reply.started":"2025-01-02T08:26:20.748386Z","shell.execute_reply":"2025-01-02T08:26:20.844313Z"}},"outputs":[{"name":"stdout","text":"trainable params: 1,146,880 || all params: 3,213,896,704 || trainable%: 0.0357\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# setting up training arguments for the model training process\ntraining_args = TrainingArguments(\n    output_dir = \"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    warmup_steps=5,\n    learning_rate=2e-4,\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    tokenizer=tokenizer,\n    args=training_args,\n    peft_config=lora_config,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:57:32.337509Z","iopub.execute_input":"2025-01-02T08:57:32.337846Z","iopub.status.idle":"2025-01-02T08:57:34.794775Z","shell.execute_reply.started":"2025-01-02T08:57:32.337821Z","shell.execute_reply":"2025-01-02T08:57:34.793942Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-43-8c8846e77e81>:13: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n  trainer = SFTTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ba5ae0b1c345fd8f9be48942382769"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f49ac57e73b54dbb9c322c04350d6fdb"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"model.train()\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T08:57:51.895703Z","iopub.execute_input":"2025-01-02T08:57:51.896027Z","iopub.status.idle":"2025-01-02T09:08:07.514277Z","shell.execute_reply.started":"2025-01-02T08:57:51.895999Z","shell.execute_reply":"2025-01-02T09:08:07.513592Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [800/800 10:13, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.595800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=800, training_loss=0.5496325302124023, metrics={'train_runtime': 615.1812, 'train_samples_per_second': 1.3, 'train_steps_per_second': 1.3, 'total_flos': 9422225526804480.0, 'train_loss': 0.5496325302124023, 'epoch': 1.0})"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"### Testing the model","metadata":{}},{"cell_type":"code","source":"def generate(category, input_prompt):\n    messages = [\n        {\"role\":\"system\", \"content\":instruction},\n        {\"role\":\"category\",\"content\":category},\n        {\"role\":\"user\",\"content\":input_prompt}\n    ]\n\n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n    outputs = model.generate(**inputs, max_new_tokens=2048, num_return_sequences=1)\n    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:20:27.282010Z","iopub.execute_input":"2025-01-02T09:20:27.282320Z","iopub.status.idle":"2025-01-02T09:20:27.287466Z","shell.execute_reply.started":"2025-01-02T09:20:27.282296Z","shell.execute_reply":"2025-01-02T09:20:27.286494Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"res = generate(\"Lost or Missing Warranty Card\", \"What should I do to get the lost warranty card?\")\nprint(res)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:20:28.172337Z","iopub.execute_input":"2025-01-02T09:20:28.172699Z","iopub.status.idle":"2025-01-02T09:20:57.482093Z","shell.execute_reply.started":"2025-01-02T09:20:28.172671Z","shell.execute_reply":"2025-01-02T09:20:57.481173Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"system\n\nCutting Knowledge Date: December 2023\nToday Date: 02 Jan 2025\n\nYou are helpful and efficient e-commerce customer support assistant bot designed to assist users by providing answers to frequently asked questions (FAQs) related to our products and services. Your responses should be concise, clear, and friendly, ensuring the user feels heard and supported. If the user’s question is outside the scope of the FAQ, gently direct them to contact customer support.\n\nAlways prioritize accuracy and clarity in your answers.\nIf the user asks a complex question, break it down into smaller, manageable parts and answer step-by-step.\nProvide useful links or references to detailed documentation when appropriate.\nUse a friendly and professional tone, ensuring the response is easy to understand.\nIf the FAQ does not cover the question, offer an apology and suggest contacting customer support.category\n\nLost or Missing Warranty Carduser\n\nWhat should I do to get the lost warranty card?assistant\n\nI'm sorry to hear that you've lost your warranty card for your [Product Name]. Don't worry, we can help you get a replacement or a new warranty card. Here are the steps you can follow:\n\n1. Check your email: First, check your email inbox and spam folder for any emails related to your warranty card. Sometimes, the email with the warranty card may be sent to your registered email address.\n\n2. Contact Customer Support: If you can't find the email, you can contact our customer support team by calling the number provided on our website or by sending an email to [support email address]. They will guide you through the process of getting a replacement or a new warranty card.\n\n3. Provide Required Information: When you contact our customer support team, please provide the following information:\n   - Your order number or the order date\n   - The product name and model number\n   - The reason for the lost warranty card\n\n4. Follow the Instructions: Our customer support team will guide you through the process of getting a replacement or a new warranty card. They may ask you to provide additional information or documentation, such as your name, address, and phone number.\n\n5. Wait for the Replacement: Once you have provided the required information, our customer support team will process your request and send you a replacement or a new warranty card. The replacement process may take a few days to a week, depending on the complexity of the request.\n\n6. Check Your Account: After you have received the replacement or new warranty card, please check your account to ensure that the new warranty card is added to your account. If it's not, please contact our customer support team to update your account.\n\nWe apologize for the inconvenience caused by the lost warranty card, and we appreciate your patience and understanding. If you have any further questions or concerns, please don't hesitate to contact us.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"model.save_pretrained(\"/content/ecom_customer_support_chatbot_llama3.2-3B\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:30:08.531357Z","iopub.execute_input":"2025-01-02T09:30:08.531788Z","iopub.status.idle":"2025-01-02T09:30:08.606415Z","shell.execute_reply.started":"2025-01-02T09:30:08.531757Z","shell.execute_reply":"2025-01-02T09:30:08.605507Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# push model to hf hub\nmodel.push_to_hub(\"ecom-customer-support-llama3-2-3B-fine-tuned\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-02T09:32:09.853870Z","iopub.execute_input":"2025-01-02T09:32:09.854201Z","iopub.status.idle":"2025-01-02T09:32:11.256074Z","shell.execute_reply.started":"2025-01-02T09:32:09.854173Z","shell.execute_reply":"2025-01-02T09:32:11.255202Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/4.60M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea012513503542588351a2fbd5485c17"}},"metadata":{}},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/avikumart/ecom-customer-support-llama3-2-3B-fine-tuned/commit/74e0aa5b5696659777ff2a965a4e6b8a1d48645f', commit_message='Upload model', commit_description='', oid='74e0aa5b5696659777ff2a965a4e6b8a1d48645f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/avikumart/ecom-customer-support-llama3-2-3B-fine-tuned', endpoint='https://huggingface.co', repo_type='model', repo_id='avikumart/ecom-customer-support-llama3-2-3B-fine-tuned'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":53}]}